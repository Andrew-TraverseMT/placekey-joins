{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Andrew-TraverseMT/placekey-joins/blob/main/CMS_hopital_and_payment_join.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HfmklC3cEIl6"
      },
      "source": [
        "# Exploring Overlap of NPI and Overture"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VRn_LZ9YEYcs"
      },
      "source": [
        "### Environment Setup to Read from Drive\n",
        "\n",
        "> Using awscli, we can pull in the skinny mappings from s3\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WfH48DdgJ0R4",
        "outputId": "57d05102-5dea-48a8-ada7-c0e41bfe9a30"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: polars in /usr/local/lib/python3.11/dist-packages (1.9.0)\n",
            "Collecting awscli\n",
            "  Downloading awscli-1.37.9-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting botocore==1.36.9 (from awscli)\n",
            "  Downloading botocore-1.36.9-py3-none-any.whl.metadata (5.7 kB)\n",
            "Collecting docutils<0.17,>=0.10 (from awscli)\n",
            "  Downloading docutils-0.16-py2.py3-none-any.whl.metadata (2.7 kB)\n",
            "Collecting s3transfer<0.12.0,>=0.11.0 (from awscli)\n",
            "  Downloading s3transfer-0.11.2-py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: PyYAML<6.1,>=3.10 in /usr/local/lib/python3.11/dist-packages (from awscli) (6.0.2)\n",
            "Collecting colorama<0.4.7,>=0.2.5 (from awscli)\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl.metadata (17 kB)\n",
            "Collecting rsa<4.8,>=3.1.2 (from awscli)\n",
            "  Downloading rsa-4.7.2-py3-none-any.whl.metadata (3.6 kB)\n",
            "Collecting jmespath<2.0.0,>=0.7.1 (from botocore==1.36.9->awscli)\n",
            "  Downloading jmespath-1.0.1-py3-none-any.whl.metadata (7.6 kB)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.11/dist-packages (from botocore==1.36.9->awscli) (2.8.2)\n",
            "Requirement already satisfied: urllib3!=2.2.0,<3,>=1.25.4 in /usr/local/lib/python3.11/dist-packages (from botocore==1.36.9->awscli) (2.3.0)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.11/dist-packages (from rsa<4.8,>=3.1.2->awscli) (0.6.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore==1.36.9->awscli) (1.17.0)\n",
            "Downloading awscli-1.37.9-py3-none-any.whl (4.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.6/4.6 MB\u001b[0m \u001b[31m28.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading botocore-1.36.9-py3-none-any.whl (13.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.3/13.3 MB\u001b[0m \u001b[31m40.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Downloading docutils-0.16-py2.py3-none-any.whl (548 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m548.2/548.2 kB\u001b[0m \u001b[31m14.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading rsa-4.7.2-py3-none-any.whl (34 kB)\n",
            "Downloading s3transfer-0.11.2-py3-none-any.whl (84 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.2/84.2 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
            "Installing collected packages: rsa, jmespath, docutils, colorama, botocore, s3transfer, awscli\n",
            "  Attempting uninstall: rsa\n",
            "    Found existing installation: rsa 4.9\n",
            "    Uninstalling rsa-4.9:\n",
            "      Successfully uninstalled rsa-4.9\n",
            "  Attempting uninstall: docutils\n",
            "    Found existing installation: docutils 0.21.2\n",
            "    Uninstalling docutils-0.21.2:\n",
            "      Successfully uninstalled docutils-0.21.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "sphinx 8.1.3 requires docutils<0.22,>=0.20, but you have docutils 0.16 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed awscli-1.37.9 botocore-1.36.9 colorama-0.4.6 docutils-0.16 jmespath-1.0.1 rsa-4.7.2 s3transfer-0.11.2\n"
          ]
        }
      ],
      "source": [
        "!pip install polars awscli"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!aws s3 --no-sign-request cp s3://placekey-free-datasets/hospital-payment-value-data-from-cms/csv/hospital-payment-value-data-from-cms.csv /content/data/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Im80DQjsyVtL",
        "outputId": "f402f83a-5506-40b3-e9cb-353cc8070271"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "download: s3://placekey-free-datasets/hospital-payment-value-data-from-cms/csv/hospital-payment-value-data-from-cms.csv to data/hospital-payment-value-data-from-cms.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!aws s3 --no-sign-request cp s3://placekey-free-datasets/hospital-data-from-cms/csv/hospital-data-from-cms.csv /content/data/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3T8PIg0_yXls",
        "outputId": "3c4413a0-962e-432a-f88e-0b28708a2203"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "download: s3://placekey-free-datasets/hospital-data-from-cms/csv/hospital-data-from-cms.csv to data/hospital-data-from-cms.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nUZ6TXIhFFfZ"
      },
      "source": [
        "### Diving into the Join\n",
        "\n",
        "> At this point, you have both files to begin the join `/content/data/hospital-payment-value-data-from-cms.csv` and `/content/data/hospital-data-from-cms.csv`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "1D9YsqGUAxEB"
      },
      "outputs": [],
      "source": [
        "# defining a function to calculate the percent of records that are not null\n",
        "\n",
        "def pct_not_null(df, column_name):\n",
        "    total_non_null = df.select(pl.col(column_name).is_not_null().sum()).to_numpy()[0, 0]\n",
        "    total_rows = df.height\n",
        "    pct_non_null = (total_non_null / total_rows) * 100\n",
        "    return round(pct_non_null, 2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LT6eWYvZF5Ks"
      },
      "source": [
        "### Joining the Values\n",
        "> Now, we can complete the join. Here we are joining hospital payment value data from CMS (right) to hospital data from CMS (left). To promote more exploration, we compute two joins: placekey which provides location_name + address and address_placekey which joins on address."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "VgyjgSOsC3wT"
      },
      "outputs": [],
      "source": [
        "import polars as pl\n",
        "\n",
        "payments = pl.read_csv(\n",
        "    '/content/data/hospital-payment-value-data-from-cms.csv',\n",
        "    schema_overrides={\n",
        "        'Payment Footnote': pl.Utf8,\n",
        "        'Value of Care Footnote': pl.Utf8\n",
        "        }  # Specify dtype for 'Payment Footnote'\n",
        ")\n",
        "payments_placekeys = payments[\"placekey\"].to_list()\n",
        "payments_address_placekeys = payments[\"address_placekey\"].to_list()\n",
        "\n",
        "hospital = pl.scan_csv('/content/data/hospital-data-from-cms.csv').filter(\n",
        "            pl.col(\"placekey\").is_in(payments_placekeys) | pl.col(\"address_placekey\").is_in(payments_address_placekeys)\n",
        "        ).collect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QKY-Mdl3-XAW",
        "outputId": "c50aee45-f8d0-47bb-edd9-189399397442"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NPI values in Overture matched on location name and address: 8.77%\n",
            "NPI values in Overture matched on address: 24.73%\n"
          ]
        }
      ],
      "source": [
        "import polars as pl\n",
        "npi_joined_overture_placekey = npi.join(overture, \"placekey\", \"left\")\n",
        "npi_joined_overture_address_placekey = npi.unique(\"address_placekey\").join(overture.unique(\"address_placekey\"), \"address_placekey\", \"left\")\n",
        "#delete npi here for memory optimzation\n",
        "#delete overture here for memory optimzation\n",
        "del npi\n",
        "del overture\n",
        "# NPI values in Overture matched on location name and address: 8.91%\n",
        "print(f\"NPI values in Overture matched on location name and address: \" + str(pct_not_null(npi_joined_overture_placekey,\"id\")) + \"%\")\n",
        "# NPI values in Overture matched on address: 24.75%\n",
        "print(f\"NPI values in Overture matched on address: \" + str(pct_not_null(npi_joined_overture_address_placekey,\"id\")) + \"%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TNv2nXvTOGfV"
      },
      "source": [
        "### Pulling in the Overture Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jZGgYa46OJm-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7b8539cb-040d-418e-b637-a9df1a5bf025"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "download: s3://overturemaps-us-west-2/release/2024-02-15-alpha.0/theme=places/type=place/part-00003-2b783cb2-68a1-40a4-bc0c-2b129577f97b-c000.zstd.parquet to data/latest/part-00003-2b783cb2-68a1-40a4-bc0c-2b129577f97b-c000.zstd.parquet\n",
            "download: s3://overturemaps-us-west-2/release/2024-02-15-alpha.0/theme=places/type=place/part-00001-2b783cb2-68a1-40a4-bc0c-2b129577f97b-c000.zstd.parquet to data/latest/part-00001-2b783cb2-68a1-40a4-bc0c-2b129577f97b-c000.zstd.parquet\n",
            "download: s3://overturemaps-us-west-2/release/2024-02-15-alpha.0/theme=places/type=place/part-00000-2b783cb2-68a1-40a4-bc0c-2b129577f97b-c000.zstd.parquet to data/latest/part-00000-2b783cb2-68a1-40a4-bc0c-2b129577f97b-c000.zstd.parquet\n",
            "download: s3://overturemaps-us-west-2/release/2024-02-15-alpha.0/theme=places/type=place/part-00004-2b783cb2-68a1-40a4-bc0c-2b129577f97b-c000.zstd.parquet to data/latest/part-00004-2b783cb2-68a1-40a4-bc0c-2b129577f97b-c000.zstd.parquet\n",
            "download: s3://overturemaps-us-west-2/release/2024-02-15-alpha.0/theme=places/type=place/part-00005-2b783cb2-68a1-40a4-bc0c-2b129577f97b-c000.zstd.parquet to data/latest/part-00005-2b783cb2-68a1-40a4-bc0c-2b129577f97b-c000.zstd.parquet\n",
            "download: s3://overturemaps-us-west-2/release/2024-02-15-alpha.0/theme=places/type=place/part-00002-2b783cb2-68a1-40a4-bc0c-2b129577f97b-c000.zstd.parquet to data/latest/part-00002-2b783cb2-68a1-40a4-bc0c-2b129577f97b-c000.zstd.parquet\n"
          ]
        }
      ],
      "source": [
        "!aws s3 --no-sign-request cp s3://overturemaps-us-west-2/release/2024-02-15-alpha.0/theme=places/type=place/ /content/data/latest --recursive"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import polars as pl\n",
        "import os\n",
        "\n",
        "ids_to_retrieve = list(set(filter(lambda item: item is not None,  (npi_joined_overture_placekey[\"id\"].to_list() + npi_joined_overture_address_placekey[\"id\"].to_list()))))\n",
        "directory = '/content/data/latest'\n",
        "dataframes = []\n",
        "for filename in os.listdir(directory):\n",
        "    if filename.endswith('.parquet'):\n",
        "        file_path = os.path.join(directory, filename)\n",
        "        df = pl.scan_parquet(file_path).filter(\n",
        "            pl.col(\"id\").is_in(ids_to_retrieve)\n",
        "        ).collect()\n",
        "        dataframes.append(df)\n",
        "overture_df = pl.concat([df for df in dataframes])"
      ],
      "metadata": {
        "id": "wPJz6Jn7GxxK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from shapely import wkb\n",
        "import folium\n",
        "import html\n",
        "\n",
        "def wkb_to_lon_lat(wkb_point):\n",
        "    point = wkb.loads(wkb_point)\n",
        "    return point.x, point.y\n",
        "\n",
        "def format_label(row):\n",
        "    label_parts = []\n",
        "    for key, value in row.items():\n",
        "        if key in ['npi','names','phones','websites','socials', 'confidence', 'id']:\n",
        "            sanitized_value = html.escape(str(value))\n",
        "            label_parts.append(f\"{key}: {sanitized_value}\")\n",
        "    label = ', '.join(label_parts)\n",
        "    return label\n",
        "\n",
        "def create_map(df_pre, region_filter, locality_filter):\n",
        "  def filter_by_address(row, locality_filter, region_filter):\n",
        "    first_address = row['addresses'][0]\n",
        "    locality = first_address.get('locality')\n",
        "    region = first_address.get('region')\n",
        "    return (locality in locality_filter) and (region in region_filter)\n",
        "\n",
        "  df = df_pre[df_pre.apply(filter_by_address, axis=1, locality_filter=locality_filter, region_filter=region_filter)]\n",
        "  map_center = [df['latitude'].mean(), df['longitude'].mean()]\n",
        "  m = folium.Map(location=map_center, zoom_start=12)\n",
        "\n",
        "  for idx, row in df.iterrows():\n",
        "      lat = float(row['latitude'])\n",
        "      lon = float(row['longitude'])\n",
        "      label = str(format_label(row))\n",
        "      folium.Marker([lat, lon], popup=label).add_to(m)\n",
        "\n",
        "  return m"
      ],
      "metadata": {
        "id": "FcocyIHJHANL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "region_filter = [\"NJ\"]\n",
        "locality_filter=[\"Jersey City\", \"Hoboken\"]"
      ],
      "metadata": {
        "id": "aoS0237HHWUQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "npi_joined_overture_placekey_with_overture = npi_joined_overture_placekey.join(overture_df, \"id\", \"left\").filter(pl.col(\"id\").is_not_null()).to_pandas()\n",
        "npi_joined_overture_placekey_with_overture[['longitude', 'latitude']] = npi_joined_overture_placekey_with_overture.apply(lambda row: wkb_to_lon_lat(row['geometry']), axis=1, result_type='expand')\n",
        "del npi_joined_overture_placekey\n",
        "del overture_df"
      ],
      "metadata": {
        "id": "MK_j3d-XHYT4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "create_map(npi_joined_overture_placekey_with_overture, region_filter, locality_filter)"
      ],
      "metadata": {
        "id": "NdCBSJCQaKf_"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}