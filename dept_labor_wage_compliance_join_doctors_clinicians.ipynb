{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Andrew-TraverseMT/placekey-joins/blob/main/dept_labor_wage_compliance_join_doctors_clinicians.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Joining Department of Labor Wage and Hour Compliance data with National Downloadable Files from the Doctors and Clinicians Data section using Placekey\n",
        "This notebook demonstrates how to combine using Placekey for location-based joins. Understanding this relationship can help in."
      ],
      "metadata": {
        "id": "vpZ_c1f0HS-Z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Installing Dependencies and Importing Libraries"
      ],
      "metadata": {
        "id": "mqnVwyzHoRaz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ScnzClV7oDmd",
        "outputId": "08c7c7a3-9acf-4c74-e8b4-cbe519e9d468"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting placekey\n",
            "  Downloading placekey-0.0.36-py3-none-any.whl.metadata (8.1 kB)\n",
            "Collecting h3<5,>=4.2.1 (from placekey)\n",
            "  Downloading h3-4.2.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (18 kB)\n",
            "Requirement already satisfied: shapely in /usr/local/lib/python3.11/dist-packages (from placekey) (2.0.7)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from placekey) (2.32.3)\n",
            "Collecting ratelimit (from placekey)\n",
            "  Downloading ratelimit-2.2.1.tar.gz (5.3 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting backoff (from placekey)\n",
            "  Downloading backoff-2.2.1-py3-none-any.whl.metadata (14 kB)\n",
            "Collecting boto3 (from placekey)\n",
            "  Downloading boto3-1.37.3-py3-none-any.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from placekey) (2.2.2)\n",
            "Collecting botocore<1.38.0,>=1.37.3 (from boto3->placekey)\n",
            "  Downloading botocore-1.37.3-py3-none-any.whl.metadata (5.7 kB)\n",
            "Collecting jmespath<2.0.0,>=0.7.1 (from boto3->placekey)\n",
            "  Downloading jmespath-1.0.1-py3-none-any.whl.metadata (7.6 kB)\n",
            "Collecting s3transfer<0.12.0,>=0.11.0 (from boto3->placekey)\n",
            "  Downloading s3transfer-0.11.3-py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas->placekey) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->placekey) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->placekey) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->placekey) (2025.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->placekey) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->placekey) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->placekey) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->placekey) (2025.1.31)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->placekey) (1.17.0)\n",
            "Downloading placekey-0.0.36-py3-none-any.whl (18 kB)\n",
            "Downloading h3-4.2.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m18.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
            "Downloading boto3-1.37.3-py3-none-any.whl (139 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.3/139.3 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading botocore-1.37.3-py3-none-any.whl (13.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.3/13.3 MB\u001b[0m \u001b[31m22.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
            "Downloading s3transfer-0.11.3-py3-none-any.whl (84 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.2/84.2 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: ratelimit\n",
            "  Building wheel for ratelimit (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ratelimit: filename=ratelimit-2.2.1-py3-none-any.whl size=5895 sha256=2e6609141056d202ac8ac8e1da97a5f0dcc35a68ee49bf3833b0f12242f1c483\n",
            "  Stored in directory: /root/.cache/pip/wheels/ee/d5/e5/8fbffe089140fb498987b7709becf861086daace105d243475\n",
            "Successfully built ratelimit\n",
            "Installing collected packages: ratelimit, jmespath, h3, backoff, botocore, s3transfer, boto3, placekey\n",
            "Successfully installed backoff-2.2.1 boto3-1.37.3 botocore-1.37.3 h3-4.2.1 jmespath-1.0.1 placekey-0.0.36 ratelimit-2.2.1 s3transfer-0.11.3\n"
          ]
        }
      ],
      "source": [
        "!pip install placekey"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import placekey as pk\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import geopandas as gpd\n",
        "import folium\n",
        "from datetime import datetime\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "oQnwHWLIoxgJ"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Explore Available Free Datasets using Placekey_PY"
      ],
      "metadata": {
        "id": "jfQvwdMLpTot"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "datasets = pk.list_free_datasets()\n",
        "print(datasets)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MmQmzFEqpape",
        "outputId": "a1c749ff-5533-405a-88d3-322adb3bbd14"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['anteriad-skinny-file', 'chicago-vacant-and-abandoned-buildings', 'ageon-skinny-file', 'preferred-communications-skinny-file', 'buildzoom-skinny-file', 'regrid-skinny-file', 'chipotle-locations', 'department-of-labor-wage-and-hour-compliance', 'verisk-skinny-file', 'boston-public-works-violations', 'environics-skinny-file', 'nyc-eviction-data', 'cap-locations-skinny-file', 'chicago-scofflaw-law-violation-data', 'l2-data-skinny-file', 'openaddresses', 'la-crime-2020-24', 'chicago-building-permits', 'national-address-database', 'boston-food-establishment-inspections', 'nyc-tax-liens-sale', 'national-provider-identifier', 'paycheck-protection-program-lender-locations', 'federal-real-property-data', 'philadelphia-affordable-housing-production', 'hifld-fire-department-data', 'national-downloadable-files-from-the-doctors-and-clinicians-data-section', 'foursquare-open-source-places', 'hospice-medicare-enrollments', 'skilled-nursing-facility-medicare-enrollments', 'la-county-active-businesses', 'home-health-agency-medicare-enrollments', 'philadelphia-certified-for-rental-suitability', 'starbucks-and-dunkin', 'resimplifi-skinny-file', 'federally-qualified-health-centers-provider-locations', 'hospital-payment-value-data-from-cms', 'ev-charging-station', 'rural-health-clinic-medicare-enrollments', 'supplemental-nutrition-assistance-program-locations', 'dc-healthy-corner-stores', 'home-infusion-therapy-provider-medicare-enrollments', 'hospital-medicare-enrollments', 'windfall-skinny-file', 'hifld-local-law-enforcement-locations', 'nyc-real-property-data', 'paycheck-protection-program-loan-data', 'throtle-skinny-file', 'first-american-skinny-file', 'overture', 'nyc-acris-property-locations', 'la-county-restaurant-health-inspection-data', 'philadelphia-demolitions', 'nyc-public-computer-access', 'boston-property-assessment-data', 'nyc-rpie-violations', 'nyc-garden-data', 'nyc-street-tree-census', 'nces-public-school-characteristics', 'hospital-data-from-cms']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dept_labor_dataset = [dataset for dataset in datasets if 'department-of-labor' in dataset]\n",
        "print(dept_labor_dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cuk3k5T5pwq1",
        "outputId": "01b8a85c-1aba-4444-812d-3c09b12b94c7"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['department-of-labor-wage-and-hour-compliance']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "doctors_clinicians_dataset = [dataset for dataset in datasets if 'doctors-and-clinicians' in dataset]\n",
        "print(doctors_clinicians_dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nhrToPTqIbwK",
        "outputId": "e6d36312-00c6-4f7e-8fac-157b125ef0f8"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['national-downloadable-files-from-the-doctors-and-clinicians-data-section']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Loading\n",
        "We'll load two datasets:\n",
        "- **Boston Property Assessments**: Contains property details including assessed values and location identifiers.\n",
        "- **Public Works Violations**: Records of violations issued by the public works department, useful for understanding neighborhood or property-specific issues."
      ],
      "metadata": {
        "id": "FtCzOgrHHoBO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# S3 URL location for department-of-labor-wage-and-hour-compliance\n",
        "s3_location_0 = pk.return_free_datasets_location_by_name('department-of-labor-wage-and-hour-compliance', url=True)\n",
        "print(s3_location_0)\n",
        "\n",
        "# S3 URL location for\n",
        "s3_location_1 = pk.return_free_datasets_location_by_name('national-downloadable-files-from-the-doctors-and-clinicians-data-section', url=True)\n",
        "print(s3_location_1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7K_6DSNsr-Hc",
        "outputId": "16264ee2-d587-4e34-8487-b7e3db1b989b"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "https://placekey-free-datasets.s3.us-west-2.amazonaws.com/department-of-labor-wage-and-hour-compliance/csv/department-of-labor-wage-and-hour-compliance.csv\n",
            "https://placekey-free-datasets.s3.us-west-2.amazonaws.com/national-downloadable-files-from-the-doctors-and-clinicians-data-section/csv/national-downloadable-files-from-the-doctors-and-clinicians-data-section.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Read Department of Labor data to Pandas DataFrame and inspect it\n",
        "dept_labor_df = pd.read_csv(s3_location_0, on_bad_lines='warn', low_memory=False) # handling inconsistent number of fields in some rows and mixed dtypes\n",
        "dept_labor_df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-vPfJtPDzupu",
        "outputId": "3bae7952-f721-47eb-99b0-eaea11815305"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-7-2365e3d9815c>:2: ParserWarning: Skipping line 118993: expected 118 fields, saw 119\n",
            "Skipping line 155108: expected 118 fields, saw 119\n",
            "Skipping line 283686: expected 118 fields, saw 119\n",
            "Skipping line 341625: expected 118 fields, saw 119\n",
            "\n",
            "  dept_labor_df = pd.read_csv(s3_location_0, on_bad_lines='warn', low_memory=False) # handling inconsistent number of fields in some rows and mixed dtypes\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Department of Labor dataset provides a rich collection of fields related to labor law enforcement, including quantitative metrics such as back wages owed, number of employees affected, and violation counts, as well as details tied to specific federal laws like the Fair Labor Standards Act (FLSA) and Family and Medical Leave Act (FMLA). By using Placekey, this dataset can be linked with other location-based datasets to enable diverse analyses. In this example, we will join the data to Doctors and Clinicians data to identify practices that have labor violations."
      ],
      "metadata": {
        "id": "8tVhANTRMkca"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Read property assessment data to Pandas DataFrame and inspect it\n",
        "doctors_clinicians_df = pd.read_csv(s3_location_1, on_bad_lines='warn', low_memory=False)\n",
        "doctors_clinicians_df.head()"
      ],
      "metadata": {
        "id": "sWvq_0Kn0i6z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The National Downloadable files for Doctors and Clinicians data contains a comprehensive set of information about healthcare providers, including identification information, professional credentials, specialties, national provider id ('npi), facility name, and a flag for telehealth providers. Using Placekey, we will join these datasets."
      ],
      "metadata": {
        "id": "94uUzDt3PAGU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Explore the data for insights about the Placekey join\n",
        "\n",
        "For this example, we will explore the relationships between:\n",
        "\n",
        "1.   Provider experience and back wages owed\n",
        "2.   Violation frequency and provider specialty\n",
        "\n",
        "We will create a map showing the count of violations by facility, enabled by Placekey location fields\n",
        "\n"
      ],
      "metadata": {
        "id": "3emwaWCi1I1w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the number of cases in the Department of Labor data\n",
        "case_count = len(dept_labor_df)\n",
        "print(f\"Number of cases in Department of Labor DataFrame: {case_count}\")\n",
        "\n",
        "# Calculate the number of unique address Placekeys in the Department of Labor data\n",
        "address_placekeys_left = len(dept_labor_df['address_placekey'].unique())\n",
        "print(f\"Number of unique address Placekeys in Department of Labor DataFrame: {address_placekeys_left}\")"
      ],
      "metadata": {
        "id": "SGL9xXyS1Ru_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Count the number of unique providers in the Doctors and Clinicians data\n",
        "unique_providers_count = len(doctors_clinicians_df['npi'].unique())\n",
        "print(f\"Number of unique providers in Doctors and Clinicians DataFrame: {unique_providers_count}\")\n",
        "\n",
        "# Count the number of unique address Placekeys in the Doctors and Clinicians data\n",
        "address_placekeys_right = len(doctors_clinicians_df['address_placekey'].unique())\n",
        "print(f\"Number of unique address Placekeys in Doctors and Clinicians DataFrame: {address_placekeys_right}\")"
      ],
      "metadata": {
        "id": "53wlI1Kz2IYy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate statistics about provider experience by calculating the time since graduation in the grd_yr field\n",
        "current_year = datetime.now().year\n",
        "doctors_clinicians_df['provider_experience'] = current_year - doctors_clinicians_df['grd_yr']\n",
        "\n",
        "# Set pandas display option to suppress scientific notation\n",
        "pd.set_option('display.float_format', lambda x: '%.2f' % x)\n",
        "\n",
        "# Describe the provider experience data\n",
        "print(doctors_clinicians_df['provider_experience'].describe())"
      ],
      "metadata": {
        "id": "ZsJ5mGJZSsTE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the frequency of provider primary specialties\n",
        "print(doctors_clinicians_df['pri_spec'].value_counts())"
      ],
      "metadata": {
        "id": "v-cMgObAUoHR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Group the total back wages owed by address Placekey\n",
        "back_wages_grouped = dept_labor_df.groupby('address_placekey')['bw_atp_amt'].sum().reset_index()\n",
        "back_wages_grouped.head()"
      ],
      "metadata": {
        "id": "l7a6qhKR7f5G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the total violation count by address Placekey\n",
        "violations_grouped = dept_labor_df.groupby('address_placekey')['case_violtn_cnt'].sum().reset_index()\n",
        "violations_grouped.head()"
      ],
      "metadata": {
        "id": "GaOOllBd9kqa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Joining Data\n",
        "We use Placekey for this join because:\n",
        "- It provides a standardized way to match locations across different datasets.\n",
        "- Helps in dealing with inconsistencies in address or location data."
      ],
      "metadata": {
        "id": "t5xJ83ka38mX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Percent of address Placekeys in Doctors and Clinicians data with matches in the Department of Labor violations data\n",
        "common_placekeys = doctors_clinicians_df[doctors_clinicians_df['address_placekey'].isin(dept_labor_df['address_placekey'])]\n",
        "percent_common_placekeys = (len(common_placekeys) / len(doctors_clinicians_df)) * 100\n",
        "print(f\"Percent of address Placekeys in Doctors and Clinicians data with matches in the Department of Labor violations data: {percent_common_placekeys:.2f}%\")"
      ],
      "metadata": {
        "id": "l4djGF7ci8ku"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform a join to plot provider experiance versus labor violations\n",
        "join_df = doctors_clinicians_df.merge(back_wages_grouped, on='address_placekey', how='left')\n",
        "join_df = join_df.merge(violations_grouped, on='address_placekey', how='left')"
      ],
      "metadata": {
        "id": "d_EasV2u8Iz6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "join_df.head()"
      ],
      "metadata": {
        "id": "eIzWxxgAbF0O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exploring Relationships with Graphs"
      ],
      "metadata": {
        "id": "bRq2DYi2bUZA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Bar Chart: Provider Experience vs. Labor Violations"
      ],
      "metadata": {
        "id": "sqmz_Un6bhpB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create bins for provider experience\n",
        "bins = range(0, int(join_df['provider_experience'].max()) + 5, 5)\n",
        "labels = [f\"{i}-{i+4}\" for i in bins[:-1]] # Create bin labels\n",
        "join_df['experience_bins'] = pd.cut(join_df['provider_experience'], bins=bins, labels=labels, right=False)\n",
        "\n",
        "# Calculate mean back wages owed for each experience bin\n",
        "mean_back_wages = join_df.groupby('experience_bins')['bw_atp_amt'].mean().reset_index()\n",
        "\n",
        "# Create the bar chart\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.bar(mean_back_wages['experience_bins'], mean_back_wages['bw_atp_amt'], color='skyblue')\n",
        "\n",
        "plt.xlabel('Provider Experience (Years Since Graduation)')\n",
        "plt.ylabel('Mean Total Back Wages Owed ($)')\n",
        "plt.title('Mean Total Back Wages Owed vs. Provider Experience')\n",
        "plt.xticks(rotation=45)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "JYbI_vsRbbqH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Interpretation**:\n",
        "\n",
        "This chart reflects the mean total back wages owed by employers (e.g., healthcare facilities) for labor law violations, linked to providers grouped by their years of experience. Importantly, these back wages are owed due to violations committed by the employers, not the providers themselves. The chart excludes providers who have no back wages owed. The trend suggests that:\n",
        "\n",
        "Mid-career providers (55-59 years) are associated with facilities that have the highest mean back wages owed, indicating potentially more significant or frequent labor law violations in these settings, or higher wages for more experienced providers.\n",
        "Less experienced providers (0-4 years) and highly experienced providers (60+ years) are linked to lower back wages owed, possibly reflecting differences in the types of facilities or employment arrangements they are involved with."
      ],
      "metadata": {
        "id": "DDa-xh3tg7ZV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Bar Chart: Violation Frequency by Provider Specialty"
      ],
      "metadata": {
        "id": "5H4fZ09BfCRy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Group the data by 'pri_spec' and sum the 'case_violtn_cnt'\n",
        "specialty_violations = join_df.groupby('pri_spec')['case_violtn_cnt'].sum().reset_index()\n",
        "\n",
        "# Filter out specialties with no violations\n",
        "specialty_violations = specialty_violations[specialty_violations['case_violtn_cnt'] > 0]\n",
        "\n",
        "# Sort by violation count for better visualization\n",
        "specialty_violations = specialty_violations.sort_values(by='case_violtn_cnt', ascending=False)\n",
        "\n",
        "# Filter to include only case_violtn_cnt greater than 1000000\n",
        "specialty_violations = specialty_violations[specialty_violations['case_violtn_cnt'] > 1e6]\n",
        "\n",
        "# Create the bar chart\n",
        "plt.figure(figsize=(12, 8)) # Adjust the figure size as needed\n",
        "plt.bar(specialty_violations['pri_spec'], specialty_violations['case_violtn_cnt'], color='skyblue')\n",
        "\n",
        "# Customize the plot\n",
        "plt.xlabel('Provider Specialty')\n",
        "plt.ylabel('Total Violation Count')\n",
        "plt.title('Total Violation Count by Provider Specialty')\n",
        "plt.xticks(rotation=45, ha='right')  # Rotate x-axis labels for readability\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "qYFsrO4ne7Hd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Interpretation:**\n",
        "\n",
        "The chart reveals that Physician Assistants and Nurse Practitioners are among the specialties with the highest total violation counts, which may reflect trends in workforce size, role complexity, or practice settings. Specialties with fewer than 1,000,000 total violations are not shown."
      ],
      "metadata": {
        "id": "YPW3j1gUhrmF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Preparing Data for Mapping\n",
        "\n",
        "With the joined dataset, we can look at the geographic distribution of violations associated with each property in the assessments data."
      ],
      "metadata": {
        "id": "y8YgPqyA-wJc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert to float where necessary\n",
        "join_df['geocode_latitude'] = join_df['geocode_latitude'].astype(float)\n",
        "join_df['geocode_longitude'] = join_df['geocode_longitude'].astype(float)\n",
        "# Select relevant columns for mapping\n",
        "map_data = join_df[['geocode_latitude', 'geocode_longitude', 'case_violtn_cnt', 'bw_atp_amt', 'facility_name', 'state']]\n",
        "map_data = map_data.groupby(['facility_name', 'geocode_latitude', 'geocode_longitude']).agg({'case_violtn_cnt': 'sum', 'bw_atp_amt': 'sum', 'state': 'first'}).reset_index()"
      ],
      "metadata": {
        "id": "9ggkQbiR-zUx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a GeoDataFrame\n",
        "gdf = gpd.GeoDataFrame(\n",
        "    map_data,\n",
        "    geometry=gpd.points_from_xy(map_data['geocode_longitude'], map_data['geocode_latitude'])\n",
        ")\n",
        "# Set the coordinate reference system (CRS) to WGS84, which is standard for latitude and longitude\n",
        "gdf.crs = 'EPSG:4326'"
      ],
      "metadata": {
        "id": "PE1-iPLIAd75"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Mapping Violations by Placekey with Folium"
      ],
      "metadata": {
        "id": "aVh5vShEAikz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the latitude and longitude for Boston\n",
        "ca_lat = 36.7468\n",
        "ca_lon = -119.7726\n",
        "\n",
        "# Create a base map centered around Boston\n",
        "map_center = [ca_lat, ca_lon]\n",
        "attr='© OpenStreetMap © CartoDB'\n",
        "m = folium.Map(location=map_center, zoom_start=10, tiles='cartodbpositron', attr=attr)\n",
        "\n",
        "# Filter GDF to show only facilities with city_nm = San Francisco\n",
        "gdf = gdf[gdf['state'].str.contains('CA')]"
      ],
      "metadata": {
        "id": "Jcayd3AeAn3H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate min and max values for scaling (excluding zero and negative values)\n",
        "values = gdf['case_violtn_cnt'].dropna()  # Drop null values\n",
        "min_value = values[values > 0].min()  # Exclude zero and negative values\n",
        "max_value = values.max()\n",
        "\n",
        "# Create a legend\n",
        "legend_html = \"\"\"\n",
        "     <div style=\"position: fixed;\n",
        "     bottom: 50px; left: 50px; width: 150px; height: 150px;\n",
        "     border:2px solid grey; z-index:9999; font-size:14px;\n",
        "     background-color:white;\n",
        "     \">&nbsp; Violations by Provider Facility <br>\n",
        "     &nbsp; <i class=\"fa fa-circle fa-1x\" style=\"color:green\"></i>&nbsp; No Violations <br>\n",
        "     &nbsp; <i class=\"fa fa-circle fa-1x\" style=\"color:orange\"></i>&nbsp; Violation(s) <br>\n",
        "     &nbsp; Circle size represents cumulative violation count<br>\n",
        "     </div>\n",
        "     \"\"\"\n",
        "m.get_root().html.add_child(folium.Element(legend_html))\n",
        "\n",
        "# Iterate through the GeoDataFrame and create a Circle for each point\n",
        "for index, row in gdf.iterrows():\n",
        "    # Determine the color and radius based on 'case_violtn_cnt'\n",
        "    if pd.isnull(row['case_violtn_cnt']) or row['case_violtn_cnt'] <= 0:\n",
        "        color = 'green'\n",
        "        radius = 4  # Small radius for null or non-positive values\n",
        "    else:\n",
        "        color = 'orange'\n",
        "        # Scale radius using a logarithmic scale\n",
        "        radius = 1 + 9 * np.log10(row['case_violtn_cnt'] / min_value) / np.log10(max_value / min_value)  # Adjust the base and scaling factors as needed\n",
        "\n",
        "    # Create a popup with HTML content\n",
        "    popup_html = f\"\"\"\n",
        "        <b>Facility Name:</b> {row['facility_name']}<br>\n",
        "        <b>Total Violations:</b> {row['case_violtn_cnt']}\n",
        "        <b>Total Back Wages Owed:</b> {row['bw_atp_amt']}\n",
        "    \"\"\"\n",
        "    popup = folium.Popup(popup_html, max_width=300)\n",
        "\n",
        "    folium.Circle(\n",
        "        location=[row['geometry'].y, row['geometry'].x],\n",
        "        radius=radius,\n",
        "        color=color,\n",
        "        fill=True,\n",
        "        fill_color=color,\n",
        "        fill_opacity=0.7,\n",
        "        popup=popup\n",
        "    ).add_to(m)"
      ],
      "metadata": {
        "id": "hG0cbT6eB5Zf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# display the map\n",
        "m"
      ],
      "metadata": {
        "id": "iJ56VytEFQ6Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Optionally, save the map as an html file to add it to a website\n",
        "m.save('map.html')"
      ],
      "metadata": {
        "id": "SI00Rt5zEO4q"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}